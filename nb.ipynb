{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "folder_path = \"/home/cerrion/DATATHON/data/hackathon_data\"\n",
    "files_in_folder = os.listdir(folder_path)\n",
    "\n",
    "len(files_in_folder)\n",
    "def load_documents(json_file):\n",
    "    \"\"\"Loads the JSON file.\"\"\"\n",
    "    with open(json_file, 'r') as f:\n",
    "      try:\n",
    "          data = json.load(f)\n",
    "          return data\n",
    "      except json.JSONDecodeError:\n",
    "          print(f\"Error reading {json_file}, it may not be a valid JSON file.\")\n",
    "    return []\n",
    "\n",
    "for filename in files_in_folder:\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        doc = load_documents(file_path)\n",
    "        break\n",
    "print(doc.keys())\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items_per_doc = []\n",
    "char_counts = []\n",
    "\n",
    "long_texts = []   # Pages longer than 100k characters\n",
    "sampled_texts = []  # Random sample of pages 0 < len <= 5000\n",
    "\n",
    "LONG_TEXT_THRESHOLD = 100_000\n",
    "RANDOM_SAMPLE_THRESHOLD = 5_000\n",
    "MAX_SAVED = 100\n",
    "\n",
    "random_candidates = []\n",
    "\n",
    "for filename in tqdm(files_in_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        doc = load_documents(file_path)\n",
    "\n",
    "        text_by_page = doc.get('text_by_page_url', {})\n",
    "        num_items = len(text_by_page)\n",
    "        num_items_per_doc.append(num_items)\n",
    "\n",
    "        for page_url, text in text_by_page.items():\n",
    "            \n",
    "            length = len(text)\n",
    "            char_counts.append(length)\n",
    "\n",
    "            # Save long texts\n",
    "            if length > LONG_TEXT_THRESHOLD and len(long_texts) < MAX_SAVED:\n",
    "                long_texts.append({\n",
    "                    \"source_file\": filename,\n",
    "                    \"page_url\": page_url,\n",
    "                    \"char_length\": length,\n",
    "                    \"text\": text[:1000]\n",
    "                })\n",
    "\n",
    "            # Collect candidates for random sampling\n",
    "            if length <= RANDOM_SAMPLE_THRESHOLD:\n",
    "                random_candidates.append({\n",
    "                    \"source_file\": filename,\n",
    "                    \"page_url\": page_url,\n",
    "                    \"char_length\": length,\n",
    "                    \"text\": text[:1000]\n",
    "                })\n",
    "\n",
    "# Sample randomly from eligible candidates\n",
    "sampled_texts = random.sample(random_candidates, min(len(random_candidates), MAX_SAVED))\n",
    "\n",
    "# Output paths\n",
    "base_output_path = os.path.abspath(os.path.join(folder_path, \"..\"))\n",
    "long_output_path = os.path.join(base_output_path, \"long_texts_over_100k.json\")\n",
    "short_output_path = os.path.join(base_output_path, \"short_texts_empty.json\")\n",
    "random_output_path = os.path.join(base_output_path, \"random_texts_under_5k.json\")\n",
    "\n",
    "# Save long texts\n",
    "with open(long_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(long_texts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# Save random texts\n",
    "with open(random_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(sampled_texts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Final output\n",
    "print(\"\\n📊 Summary Statistics:\")\n",
    "print(f\"Number of items (pages) per document: {num_items_per_doc}\")\n",
    "print(f\"Total number of text blocks processed: {len(char_counts)}\")\n",
    "print(f\"Example character counts per text block: {char_counts[:10]}\")\n",
    "print(f\"\\n📝 Saved {len(long_texts)} long text blocks to: {long_output_path}\")\n",
    "print(f\"📝 Saved {len(sampled_texts)} random text blocks (0 < len <= 5k) to: {random_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_array = np.array(char_counts)\n",
    "log_lengths = np.log10(lengths_array + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(log_lengths, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"log10(Text length in characters)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Text Lengths (Character Count, log-scale)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "items_array = np.array(num_items_per_doc)\n",
    "log_items = np.log10(items_array + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(log_items, bins=50, color='salmon', edgecolor='black')\n",
    "plt.xlabel(\"log10(Number of pages per document)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Pages per Document (log-scale)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items_per_doc = []\n",
    "char_counts = []\n",
    "\n",
    "long_texts = []   # Pages longer than 100k characters\n",
    "short_texts = []  # Pages with 0 characters\n",
    "sampled_texts = []  # Random sample of pages 0 < len <= 5000\n",
    "\n",
    "random_candidates = []\n",
    "\n",
    "for filename in tqdm(files_in_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        doc = load_documents(file_path)\n",
    "\n",
    "        text_by_page = doc.get('text_by_page_url', {})\n",
    "        num_items = len(text_by_page)\n",
    "        num_items_per_doc.append(num_items)\n",
    "\n",
    "        for page_url, text in text_by_page.items():\n",
    "            \n",
    "            if 'css' in text or 'json' in text:\n",
    "                continue\n",
    "            \n",
    "            length = len(text)\n",
    "            char_counts.append(length)\n",
    "\n",
    "print(\"\\n📊 Summary Statistics:\")\n",
    "print(f\"Number of items (pages) per document: {num_items_per_doc}\")\n",
    "print(f\"Total number of text blocks processed: {len(char_counts)}\")\n",
    "print(f\"Example character counts per text block: {char_counts[:10]}\")\n",
    "print(f\"\\n📝 Saved {len(long_texts)} long text blocks to: {long_output_path}\")\n",
    "print(f\"📝 Saved {len(short_texts)} short (empty) text blocks to: {short_output_path}\")\n",
    "print(f\"📝 Saved {len(sampled_texts)} random text blocks (0 < len <= 5k) to: {random_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "lengths_array = np.array(char_counts)\n",
    "log_lengths = np.log10(lengths_array + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(log_lengths, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.xlabel(\"log10(Text length in characters)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Text Lengths (Character Count, log-scale)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "items_array = np.array(num_items_per_doc)\n",
    "log_items = np.log10(items_array + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(log_items, bins=50, color='salmon', edgecolor='black')\n",
    "plt.xlabel(\"log10(Number of pages per document)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Pages per Document (log-scale)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
